import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os

''' Data PreProcessor to compute Encoder Decoder Input. 
        INPUT :     DATAPATH contains folder path where all language directories are present.
                    targetLanguage specifies the folder where the three split csv files are present. 
            
        OUTPUT :    Train split -> TrainEncoderInput, TrainDecoderInput, TrainDecoderTarget -> Each being a 3-D numpy array
                    Valid split -> ValidEncoderInput, ValidDecoderInput, ValidDecoderTarget -> Each being a 3-D numpy array
                    Test split  -> TestEncoderInput,  TestDecoderInput,  TestDecoderTarget  -> Each being a 3-D numpy array '''
class DataProcessing():

    def __init__(self, DATAPATH = 'aksharantar_sampled', sourceLanguage = 'en', targetLanguage = 'hin'):
    
        # Save the sourceLanguage and targetLanguage
        self.sourceLanguage = sourceLanguage
        self.targetLanguage = targetLanguage

        # File Path for Train CSV File
        self.trainPath = os.path.join(DATAPATH, self.targetLanguage, self.targetLanguage + "_train.csv")

        # File Path for Validation CSV File
        self.validPath = os.path.join(DATAPATH, self.targetLanguage, self.targetLanguage + "_valid.csv")

        # File Path for Test CSV File
        self.testPath = os.path.join(DATAPATH, self.targetLanguage, self.targetLanguage + "_test.csv")

        # Load the Train Data
        self.train = pd.read_csv(
            self.trainPath,
            sep = ",",
            header = None,
            names = ["source", "target"],
        )

        # Load the Validation Data
        self.valid = pd.read_csv(
            self.validPath,
            sep = ",",
            header = None,
            names = ["source", "target"],
        )

        # Load the Test Data
        self.test = pd.read_csv(
            self.testPath,
            sep = ",",
            header = None,
            names = ["source", "target"],
        )

        # Create train data -> preprocess() calls encode()
        self.trainData = self.preprocess(self.train["source"].to_list(), self.train["target"].to_list())
        
        # Store trainEncoderInput, trainDecoderInput, trainDecoderTarget, sourceVocab and targetVocab
        self.trainEncoderInput, self.trainDecoderInput,self.trainDecoderTarget, self.sourceVocab, self.targetVocab = self.trainData

        # Once the dictionaries have been populated, store and use them for further encode() functions
        self.sourceCharToInt, self.sourceIntToChar = self.sourceVocab
        self.targetCharToInt, self.targetIntToChar = self.targetVocab

        # create Valid data (only encode function is sufficient as the dictionary lookup should be kept the same)
        self.validData = self.encode(
            self.valid["source"].to_list(),
            self.valid["target"].to_list(),

            # We use the mapping we computed from TRAIN data
            list(self.sourceCharToInt.keys()),
            list(self.targetCharToInt.keys()),

            sourceCharToInt = self.sourceCharToInt,
            targetCharToInt = self.targetCharToInt,
        )

        # Store ValidEncoderInput, ValidDecoderInput, ValidDecoderTarget
        self.validEncoderInput, self.validDecoderInput, self.validDecoderTarget = self.validData

        # create Test data (only encode function is sufficient as the dictionary lookup should be kept the same)
        self.testData = self.encode(
            self.test["source"].to_list(),
            self.test["target"].to_list(),

            # We use the mapping we computed from TRAIN data
            list(self.sourceCharToInt.keys()),
            list(self.targetCharToInt.keys()),

            sourceCharToInt = self.sourceCharToInt,
            targetCharToInt = self.targetCharToInt,
        )

        # Store TestEncoderInput, TestDecoderInput, TestDecoderTarget
        self.testEncoderInput, self.testDecoderInput, self.testDecoderTarget = self.testData

    def dictionary_lookup(self, languageCharacters):
        ''' Input ->    languageCharacters : Sorted List of characters present in a language
            
            Output ->   charToInt : Dictionary that maps each character to an Integer.
                        intToChar : Dictionary that stores the reverse mapping of charToInt.'''
        
        # Create an enumeration for the characters and store it in a dictionary
        charToInt = dict([(char, i) for i, char in enumerate(languageCharacters)])

        # Store the reverse mapping of charToInt in intToChar dictionary
        intToChar = dict((i, char) for char, i in charToInt.items())

        # Return the two dictionaries
        return charToInt, intToChar

    def encode(self, sourceWords, targetWords, sourceChars, targetChars, sourceCharToInt = None, targetCharToInt = None) :
        ''' Input ->    SourceWords : List of all source words.
                        TargetWords : List of all target words.
                        sourceChars : Sorted List of source characters.
                        targetChars : Sorted List of target characters.
                        sourceCharToInt : Dictionary of source character to integer mapping.
                        sourceCharToInt : Dictionary of target character to integer mapping.
            
            Output ->   encodeInputData : 3-D Numpy Array containing Input Data for Encoder.
                        decoderInputData : 3-D Numpy Array containing Input Data for Decoder.
                        decoderTargetData : 3-D Numpy Array containing Target Data for Decoder.
                        sourceVocab (Optional) : Tuple of two dictionaries of CharToInt mapping and IntToChar mapping for Source Language.
                        targetVocab (Optional) : Tuple of two dictionaries of CharToInt mapping and IntToChar mapping for Target Language. '''
        
        # Number of unique characters in source language -> Each character is a token. Source language tokens are encoderTokens
        numEncoderTokens = len(sourceChars)

        # Number of unique characters in target language -> Each character is a token. Target language tokens are decoderTokens
        numDecoderTokens = len(targetChars)

        # Maximum length of a source word
        maxSourceLength = max([len(txt) for txt in sourceWords])

        # Maximum length of a target word
        maxTargetLength = max([len(txt) for txt in targetWords])

        print("Number of Source-Target Pairs :", len(sourceWords))
        print("Source Language Vocabulary Length (Number of Encoder Tokens)  :" , numEncoderTokens)
        print("Target Language Vocabulary length (Number of Decoder Tokens)  :" , numDecoderTokens)
        print("Max sequence length for inputs (Max Source Lang Word Length)  :" , maxSourceLength)
        print("Max sequence length for outputs (Max Source Lang Word Length) :" , maxTargetLength)

        # SourceVocab -> Pair of Two Dictionaries = 1. Dictionary of Source Char to Integer 2. Dictionary of Integer to Source Char
        sourceVocab = None

        # TargetVocab -> Pair of Two Dictionaries = 1. Dictionary of Target Char to Integer 2. Dictionary of Integer to Target Char
        targetVocab = None

        # Create the required dictionaries if not already present 
        if sourceCharToInt == None and targetCharToInt == None:
            sourceCharToInt, sourceIntToChar = self.dictionary_lookup(sourceChars)
            targetCharToInt, targetIntToChar = self.dictionary_lookup(targetChars)

            # Store the created dictionaries in sourceVocab and targetVocab respectively
            sourceVocab = (sourceCharToInt, sourceIntToChar)
            targetVocab = (targetCharToInt, targetIntToChar)

        # For each pair of source - target, we will have a matrix of size(maxSourceLength, numEncoderTokens) as input data for encoder
        encodeInputData = np.zeros((len(sourceWords), maxSourceLength, numEncoderTokens), dtype="float32")

        # For each pair of source - target, we will have a matrix of size(maxTargetLength, numDecoderTokens) as input data for decoder
        decoderInputData = np.zeros((len(sourceWords), maxTargetLength, numDecoderTokens), dtype="float32")

        # For each pair of source - target, we will have a matrix of size(maxTargetLength, numDecoderTokens) as target data for decoder -> The input and target shape is same for decoder
        decoderTargetData = np.zeros((len(sourceWords), maxTargetLength, numDecoderTokens), dtype="float32")

        # Iterate over all pairs of sourceWord - targetWord
        for pairIndex, (sourceWord, targetWord) in enumerate(zip(sourceWords, targetWords)):
            
            # Iterate over all characters in the sourceWord with timeStep from 0 -> len(sourceWord) - 1
            for timeStep, sourceChar in enumerate(sourceWord):
                encodeInputData[pairIndex, timeStep, sourceCharToInt[sourceChar]] = 1.0

            # Put spaces for remaining entries
            encodeInputData[pairIndex, timeStep + 1 :, sourceCharToInt[" "]] = 1.0
            
            # Iterate over all characters in the targetWord with timeStep from 0 -> len(targetWord) - 1
            for timeStep, char in enumerate(targetWord):
                
                # Set DecoderInputData for this timeStep
                # TODO -> Gives KeyError for characters that are present in test data but not in train data. How do we handle such characters?
                decoderInputData[pairIndex, timeStep, targetCharToInt[char]] = 1.0

                if timeStep > 0:
                    # decoderTargetData will be ahead by one timeStep and will not include the start character.
                    decoderTargetData[pairIndex, timeStep - 1, targetCharToInt[char]] = 1.0

            # Add Spaces for rest of the entries
            decoderInputData[pairIndex, timeStep + 1 :, targetCharToInt[" "]] = 1.0
            decoderTargetData[pairIndex, timeStep:, targetCharToInt[" "]] = 1.0

        # SourceVocab and TargetVocab are not None if they were just populated by newly created dictionaries. So we return them for further use.
        if sourceVocab != None and targetVocab != None:
            return encodeInputData, decoderInputData, decoderTargetData, sourceVocab, targetVocab
        
        # Source and TargetVocab were not created in the function. 
        # This implies sourceCharToInt and targetCharToInt were not None. Hence the vocab info is already present and we don't return the two tuples.
        else:
            return encodeInputData, decoderInputData, decoderTargetData

    def preprocess(self, source, target) :
        ''' Input ->    Source : Source Column of DataSet converted to a list.
                        Target : Target Column of DataSet converted to a list.    
                        
            Output ->   Computes the lists :    source (list of all source words)
                                                target (list of all target words)
                                                sourceChars (sorted list of all source chars)
                                                targetChars (sorted list of all target chars)
                                                
                        Calls and returns the encode() function with above 4 lists passed as parameters. '''
        
        # Sets of unique characters present in all source language words and all target language words
        sourceChars = set()
        targetChars = set()

        # Converting each element of list to string 
        source = [str(x) for x in source]
        target = [str(x) for x in target]

        # Populate SourceChars Set
        for src in source :
            for char in src:
                sourceChars.add(char)

        # Populate TargetChars Set
        for tgt in target :
            for char in tgt:
                targetChars.add(char)

        # Sort the characters in source and target languages
        sourceChars = sorted(list(sourceChars))
        targetChars = sorted(list(targetChars))

        # Add space to both sets to avoid errors during encoding
        sourceChars.append(" ")
        targetChars.append(" ")

        return self.encode(source, target, sourceChars, targetChars)

dataProcessor = DataProcessing()